{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ringkasan Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import the Libraries"
      ],
      "metadata": {
        "id": "1xAKeObhZQYE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e54Rxm0J49jv"
      },
      "outputs": [],
      "source": [
        "#import data manipulation packages\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import deep learning tools \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download File Zip Dataset"
      ],
      "metadata": {
        "id": "EHnmVyxrZU4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1k5pNW5OhEXkDcjaKmuabF8WXdd9uX5zd' -O 'EYEAM_Image_Data.zip'\n",
        "#!wget -O file https://googledrive.com/host/1k5pNW5OhEXkDcjaKmuabF8WXdd9uX5zd\n",
        "!gdown --id 1k5pNW5OhEXkDcjaKmuabF8WXdd9uX5zd -O /tmp/EYEAM_Image_Data.zip\n",
        "#!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1AnsoyBESGSYzRvbMQh5-FWJdgtTo_gOj' -O 'Kijij Listings - edited.xlsx'"
      ],
      "metadata": {
        "id": "OU72y0XTT0r1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b50176-8a91-4bfb-a519-727295064f98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k5pNW5OhEXkDcjaKmuabF8WXdd9uX5zd\n",
            "To: /tmp/EYEAM_Image_Data.zip\n",
            "100% 369M/369M [00:01<00:00, 199MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extract File Zip Dataset"
      ],
      "metadata": {
        "id": "1A4TGIAqgvs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_zip = '/tmp/EYEAM_Image_Data.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "AslKRLrHgnLr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_path = '/tmp/EYEAM Image Data'\n",
        "\n",
        "source_path_binturong = os.path.join(source_path, \"Binturong\")\n",
        "source_path_koala = os.path.join(source_path, \"Koala\")\n",
        "source_path_sanfords_brown_lemur = os.path.join(source_path, \"Sanford_s Brown Lemur\")\n",
        "source_path_siau_island_tarsier = os.path.join(source_path, \"Siau Island Tarsier\")\n",
        "source_path_walrus = os.path.join(source_path, \"Walrus\")\n",
        "\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_binturong))} images of Binturong.\")\n",
        "print(f\"There are {len(os.listdir(source_path_koala))} images of Koala.\")\n",
        "print(f\"There are {len(os.listdir(source_path_sanfords_brown_lemur))} images of Sanford's Brown Lemur.\")\n",
        "print(f\"There are {len(os.listdir(source_path_siau_island_tarsier))} images of Siau Island Tarsier.\")\n",
        "print(f\"There are {len(os.listdir(source_path_walrus))} images of Walrus.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IzbmTyvif2Q",
        "outputId": "6a9a97fc-03e2-4e1f-9a89-a4baa8b8afd4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 55 images of Binturong.\n",
            "There are 50 images of Koala.\n",
            "There are 50 images of Sanford's Brown Lemur.\n",
            "There are 50 images of Siau Island Tarsier.\n",
            "There are 50 images of Walrus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define root directory\n",
        "root_dir = '/tmp/endangered-animals'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "# GRADED FUNCTION: create_train_test_dirs\n",
        "def create_train_test_dirs(root_path):\n",
        "  ### START CODE HERE\n",
        "  training_dir = os.path.join(root_path, \"training\")\n",
        "  testing_dir  = os.path.join(root_path, \"testing\")\n",
        "\n",
        "  training_binturongs_dir = os.path.join(training_dir, \"binturongs\")\n",
        "  training_koalas_dir = os.path.join(training_dir, \"koalas\")\n",
        "  training_sanfords_brown_lemurs_dir = os.path.join(training_dir, \"sanford_s_brown_lemurs\")\n",
        "  training_siau_island_tarsiers_dir = os.path.join(training_dir, \"siau_island_tarsiers\")\n",
        "  training_walruses_dir = os.path.join(training_dir, \"walruses\")\n",
        "  \n",
        "  testing_binturongs_dir = os.path.join(testing_dir, \"binturongs\")\n",
        "  testing_koalas_dir = os.path.join(testing_dir, \"koalas\")\n",
        "  testing_sanfords_brown_lemurs_dir = os.path.join(testing_dir, \"sanford_s_brown_lemurs\")\n",
        "  testing_siau_island_tarsiers_dir = os.path.join(testing_dir, \"siau_island_tarsiers\")\n",
        "  testing_walruses_dir = os.path.join(testing_dir, \"walruses\")\n",
        "\n",
        "  os.makedirs(training_binturongs_dir, exist_ok = True)\n",
        "  os.makedirs(training_koalas_dir, exist_ok = True)\n",
        "  os.makedirs(training_sanfords_brown_lemurs_dir, exist_ok = True)\n",
        "  os.makedirs(training_siau_island_tarsiers_dir, exist_ok = True)\n",
        "  os.makedirs(training_walruses_dir, exist_ok = True)\n",
        "  \n",
        "  os.makedirs(testing_binturongs_dir, exist_ok = True)\n",
        "  os.makedirs(testing_koalas_dir, exist_ok = True)\n",
        "  os.makedirs(testing_sanfords_brown_lemurs_dir, exist_ok = True)\n",
        "  os.makedirs(testing_siau_island_tarsiers_dir, exist_ok = True)\n",
        "  os.makedirs(testing_walruses_dir, exist_ok = True)\n",
        "  # HINT:\n",
        "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
        "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
        "\n",
        "  pass\n",
        "  \n",
        "  ### END CODE HERE\n",
        "\n",
        "  \n",
        "try:\n",
        "  create_train_test_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ],
      "metadata": {
        "id": "_ZCpxzD0wJQo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your create_train_test_dirs function\n",
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-McZ8rkPzexD",
        "outputId": "25e581cd-8e96-432e-91d6-211b5a9d2992"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/endangered-animals/testing\n",
            "/tmp/endangered-animals/training\n",
            "/tmp/endangered-animals/testing/binturongs\n",
            "/tmp/endangered-animals/testing/sanford_s_brown_lemurs\n",
            "/tmp/endangered-animals/testing/walruses\n",
            "/tmp/endangered-animals/testing/siau_island_tarsiers\n",
            "/tmp/endangered-animals/testing/koalas\n",
            "/tmp/endangered-animals/training/binturongs\n",
            "/tmp/endangered-animals/training/sanford_s_brown_lemurs\n",
            "/tmp/endangered-animals/training/walruses\n",
            "/tmp/endangered-animals/training/siau_island_tarsiers\n",
            "/tmp/endangered-animals/training/koalas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import copyfile\n",
        "# GRADED FUNCTION: split_data\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "  files = []\n",
        "  for file_name in os.listdir(SOURCE):\n",
        "    the_file = SOURCE + file_name\n",
        "    if os.path.getsize(the_file) > 0:\n",
        "      files.append(file_name)\n",
        "    else:\n",
        "      print(file_name + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[:testing_length]\n",
        "\n",
        "  ### START CODE HERE\n",
        "  for file_name in training_set:\n",
        "    file_this = SOURCE + file_name\n",
        "    dest     = TRAINING + file_name\n",
        "    copyfile(file_this, dest)\n",
        "\n",
        "  for file_name in testing_set:\n",
        "      file_this = SOURCE + file_name\n",
        "      dest     = TESTING + file_name\n",
        "      copyfile(file_this, dest)\n",
        "  pass\n",
        "\n",
        "\n",
        "  ### END CODE HERE"
      ],
      "metadata": {
        "id": "dzntwzsD0pad"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your split_data function\n",
        "\n",
        "# Define paths\n",
        "BINTURONGS_SOURCE_DIR = \"/tmp/EYEAM Image Data/Binturong/\"\n",
        "KOALAS_SOURCE_DIR = \"/tmp/EYEAM Image Data/Koala/\"\n",
        "SANFORD_S_BROWN_LEMURS_SOURCE_DIR = \"/tmp/EYEAM Image Data/Sanford_s Brown Lemur/\"\n",
        "SIAU_ISLAND_TARSIERS_SOURCE_DIR = \"/tmp/EYEAM Image Data/Siau Island Tarsier/\"\n",
        "WALRUSES_SOURCE_DIR = \"/tmp/EYEAM Image Data/Walrus/\"\n",
        "\n",
        "TRAINING_DIR = \"/tmp/endangered-animals/training/\"\n",
        "TESTING_DIR = \"/tmp/endangered-animals/testing/\"\n",
        "\n",
        "TRAINING_BINTURONGS_DIR = os.path.join(TRAINING_DIR, \"binturongs/\")\n",
        "TESTING_BINTURONGS_DIR = os.path.join(TESTING_DIR, \"binturongs/\")\n",
        "\n",
        "TRAINING_KOALAS_DIR = os.path.join(TRAINING_DIR, \"koalas/\")\n",
        "TESTING_KOALAS_DIR = os.path.join(TESTING_DIR, \"koalas/\")\n",
        "\n",
        "TRAINING_SANFORD_S_BROWN_LEMURS_DIR = os.path.join(TRAINING_DIR, \"sanford_s_brown_lemurs/\")\n",
        "TESTING_SANFORD_S_BROWN_LEMURS_DIR = os.path.join(TESTING_DIR, \"sanford_s_brown_lemurs/\")\n",
        "\n",
        "TRAINING_SIAU_ISLAND_TARSIERS_DIR = os.path.join(TRAINING_DIR, \"siau_island_tarsiers/\")\n",
        "TESTING_SIAU_ISLAND_TARSIERS_DIR = os.path.join(TESTING_DIR, \"siau_island_tarsiers/\")\n",
        "\n",
        "TRAINING_WALRUSES_DIR = os.path.join(TRAINING_DIR, \"walruses/\")\n",
        "TESTING_WALRUSES_DIR = os.path.join(TESTING_DIR, \"walruses/\")\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "if len(os.listdir(TRAINING_BINTURONGS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_BINTURONGS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_KOALAS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_KOALAS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_SANFORD_S_BROWN_LEMURS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_SANFORD_S_BROWN_LEMURS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_SIAU_ISLAND_TARSIERS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_SIAU_ISLAND_TARSIERS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_WALRUSES_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_WALRUSES_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "if len(os.listdir(TESTING_BINTURONGS_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_BINTURONGS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_KOALAS_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_KOALAS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_SANFORD_S_BROWN_LEMURS_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_SANFORD_S_BROWN_LEMURS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_SIAU_ISLAND_TARSIERS_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_SIAU_ISLAND_TARSIERS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_WALRUSES_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_WALRUSES_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .9\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_data(BINTURONGS_SOURCE_DIR, TRAINING_BINTURONGS_DIR, TESTING_BINTURONGS_DIR, split_size)\n",
        "split_data(KOALAS_SOURCE_DIR, TRAINING_KOALAS_DIR, TESTING_KOALAS_DIR, split_size)\n",
        "split_data(SANFORD_S_BROWN_LEMURS_SOURCE_DIR, TRAINING_SANFORD_S_BROWN_LEMURS_DIR, TESTING_SANFORD_S_BROWN_LEMURS_DIR, split_size)\n",
        "split_data(SIAU_ISLAND_TARSIERS_SOURCE_DIR, TRAINING_SIAU_ISLAND_TARSIERS_DIR, TESTING_SIAU_ISLAND_TARSIERS_DIR, split_size)\n",
        "split_data(WALRUSES_SOURCE_DIR, TRAINING_WALRUSES_DIR, TESTING_WALRUSES_DIR, split_size)\n",
        "\n",
        "# Check that the number of images matches the expected output\n",
        "print(f\"There are {len(os.listdir(TRAINING_BINTURONGS_DIR))} images of binturongs for training\")\n",
        "print(f\"There are {len(os.listdir(TESTING_BINTURONGS_DIR))} images of binturongs for testing\")\n",
        "\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_KOALAS_DIR))} images of koalas for training\")\n",
        "print(f\"There are {len(os.listdir(TESTING_KOALAS_DIR))} images of koalas for testing\")\n",
        "\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_SANFORD_S_BROWN_LEMURS_DIR))} images of sanford's brown_lemurs for training\")\n",
        "print(f\"There are {len(os.listdir(TESTING_SANFORD_S_BROWN_LEMURS_DIR))} images of sanford's brown_lemurs for testing\")\n",
        "\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_SIAU_ISLAND_TARSIERS_DIR))} images of siau island tarsiers for training\")\n",
        "print(f\"There are {len(os.listdir(TESTING_SIAU_ISLAND_TARSIERS_DIR))} images of siau island tarsiers for testing\")\n",
        "\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_WALRUSES_DIR))} images of walruses for training\")\n",
        "print(f\"There are {len(os.listdir(TESTING_WALRUSES_DIR))} images of walruses for testing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xRFqHP41xA0",
        "outputId": "eea4abbc-52e8-4672-d725-49b9847fb3ab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 38 images of binturongs for training\n",
            "There are 17 images of binturongs for testing\n",
            "\n",
            "\n",
            "There are 35 images of koalas for training\n",
            "There are 15 images of koalas for testing\n",
            "\n",
            "\n",
            "There are 35 images of sanford's brown_lemurs for training\n",
            "There are 15 images of sanford's brown_lemurs for testing\n",
            "\n",
            "\n",
            "There are 35 images of siau island tarsiers for training\n",
            "There are 15 images of siau island tarsiers for testing\n",
            "\n",
            "\n",
            "There are 35 images of walruses for training\n",
            "There are 15 images of walruses for testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  train_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "  # Pass in the appropiate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=20,\n",
        "                                                      class_mode=\"binary\",\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "  # Pass in the appropiate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                      batch_size=20,\n",
        "                                                      class_mode=\"binary\",\n",
        "                                                      target_size=(150, 150))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "zkoW6hSzBdMx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, TESTING_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4jEdWGSBgjk",
        "outputId": "a37c57f5-c34f-4729-a1e6-5990325ac5b2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 178 images belonging to 5 classes.\n",
            "Found 77 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: create_model\n",
        "def create_model():\n",
        "  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
        "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
        "\n",
        "  ### START CODE HERE\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "  # YOUR CODE HERE\n",
        "      tf.keras.layers.Conv2D(32,(3,3), activation = 'relu', input_shape=(150,150,3)),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(64,(3,3), activation = 'relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128,(3,3), activation = 'relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(512, activation = 'relu'),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "\n",
        "  \n",
        "  model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy']) \n",
        "    \n",
        "  ### END CODE HERE\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "jTI1dJKIBkED"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the untrained model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "# Note that this may take some time.\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch = 40,\n",
        "                    epochs=15,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps = 27,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eybL9bGoBpeb",
        "outputId": "88c710b4-7702-4c61-836c-f7a8b324ab3f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            " 9/40 [=====>........................] - ETA: 18s - loss: -526.3801 - accuracy: 0.1798WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 600 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 27 batches). You may need to use the repeat() function when building your dataset.\n",
            "40/40 [==============================] - 13s 290ms/step - loss: -526.3801 - accuracy: 0.1798 - val_loss: -2487.1135 - val_accuracy: 0.1948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j-h_Uanenpoo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}